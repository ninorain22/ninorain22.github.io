## Tuning Spark
由于大多数Spark计算的内存性质，Spark程序可能由集群中的任何资源导致瓶颈，通常，如果有合适的内存，瓶颈就是网络带宽。

有时，还需要以序列化形式存储RDD来减少内存使用。

这里讲主要说明两个主题
+ 数据序列化
+ 内存调优

### Data Serialization
很慢的将对象序列化或者消费大量字节的格式将会大大减慢计算速度，因此，这里可能是优化Spark程序的第一个入手点。
Spark提供两种序列化库
+ Java Serialization: 默认使用
+ Kryo Serialization: 比Java Serialization要快很多，而且更紧凑，但不支持所有的Serializable类型

可以使用`sparkConf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")来设置。这个配置将不仅用于工作节点之间的数据shuffle.
也可以用于将RDD序列化到磁盘。没有使用Kryo作为默认的唯一原因是因为自定义注册要求。

但是，**建议在任何网络密集型应用程序中使用Kryo**。
```scala
import org.apache.spark._
val conf = new SparkConf().setMaster(...).setAppName(...)
conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))
val sc = new SparkContext(conf)
```
如果对象很大，可能还要增加`sparl.kryoserializer.buffer`配置。这个值需要足够大到容纳将序列化的对象

如果没有注册自定义类，Kryo也可以工作，但是它必须存储每个对象的完整类名称，这会导致很多浪费

### Memory Tuning
在调整内存使用中，有三个方面的考虑：
1. 对象使用内存的`量`
2. 访问这些对象的`成本`
3. `垃圾回收`的开销

一般情况下，Java对象的访问很快速，但是往往会消耗掉比原始数据多出2~5倍的空间

这里从Spark的内存管理概述开始，讨论用户可以采取的具体策略，以便在应用程序中更有效的使用内存。

#### Memory Management Overview
Spark中的内存使用大部分属于两类：执行和存储。
在Spark中，执行和存储共享一块区域(M)，当没有执行内存需求时，存储可以获取所有的可利用空间，反之亦然。

在当总的存储内存量小于一个阈值(R)时，执行内存可以驱逐存储内存，R描述的M空间将永远不会被驱逐。存储无法驱逐执行。

这种设计确保了几点:
1. 不使用缓存的应用程序可以将整个空间用于执行，从而避免不必要的溢出到磁盘
2. 使用缓存的应用程序可以保留最小的存储空间R，其中数据块不受驱逐
3. 为各种工作负载提供了合理的即用性能，因为典型的用户不需要去调整它们(M和R)，默认值适用于大多数的工作负载

+ `spark.memory.fraction`: 表示大小`M`的一小部分，默认为0.6（60%）, 剩余的额40%空间用于用户数据结构、Spark中的内部元数据、
以及用户保护OOM错误的稀疏和异常大的记录 
+ `spark.memory.storageFraction`: 表示大小`R`为`M`的一部分,默认0.5(50%), R是存储区域中免于被执行驱逐的空间


#### Determining Memory Consumption
减少内存消耗的最佳方法，是创建RDD，将其放入缓存，查看Web UI中的存储页面，该页面会告诉RDD占了多少内存
为了估计特定对象的内存消耗，使用`SizeEstimator's estimate`方法，这将用于在不同数据分布的环境下缩减内存使用，
同样也可以用于决定一个广播变量在每个executor的堆上所占的空间

#### Tuning Data Structures
避免添加消耗较大的java功能，比如基于指针的数据结构和封装对象，有以下几种方法来处理:
1. 优先使用数组以及基本类型来设置数据结构，而不是标准的java或scala集合类(HashMap等)。`fastutil`提供了与标准java库兼容的集合类以及基础类型
2. 避免使用很多小对象和指针的嵌套结构
3. 使用数字ID或枚举对象而不是字符串来作为keys
4. 如果RAM小于32GB，使用JVM flag -XX:+UseCompressedOops来将指针使用4个字节存储而不是8个字节。

#### Serialized RDD Storage
在使用这种调整后，如果你的对象仍然太大而无法高效的存储，可以使用一个更简单的方案来缩减内存使用，就是以序列化的格式来存储它们。

在RDD持久化API中使用序列化存储级别来设置，比如`MEMORY_ONLY_SER`.
Spark将为每个RDD的分区存储为一个大的字节数组，这种方法唯一的去诶单就是访问序列化格式的数据较慢，因为必须要先反序列化。

如果使用序列化格式来缓存数据，强烈推荐使用`Kryo`。

#### Garbage Collection Tuning
JVM的垃圾回收成本与JAVA对象的数量成正比，因此，使用较少对象的数据结构的GC成本就更低。

一个更好的办法是`persist`上面的序列化对象。

在尝试其他技术之前，先检查下GC是不是有问题，如果有问题，使用序列化缓存

### Other Considerations

#### Level of Parallelism
如果每个操作的并行度不高，那么集群就没有得到充分的利用。Spark会自动根据每个文件大小来设置task的数量。
可以通过参数来设置并行度，或者`spark.default.parallelism`来设置。
一般而言，我们建议每个CPU核设置2~3个task

#### Memory Usage of Reduce Tasks
有时候会得到一个OOM错误，那是因为RDD超过了内存，可能是因为其中一个task的工作集太大（比如说`groupByKey`中的一个reduce task)
Spark的shuffle操作会创建一个很大的hash表来为每个task分组，因此这个表是很大的。

最简单的解决方案就是**增加并行度**，因此每个task的输入集就更小。Spark可以有效的支持最短到200ms的task。
因为Spark会在多个task之间复用一个JVM executor，因此重新启动task的代价很小，因此，可以放心的将并行度提高到甚至超过集群中CPU核心的个数

#### Broadcasting Large Variables
可以使用广播变量来减少每个序列化任务的大小。如果任务中使用的驱动程序中任何大的对象，请考虑将其实现为广播变量

Spark会在master上打印每个任务的序列化大小，一般>20KB的才值得优化

#### Data Locality
数据本地化是指数据和代码处理有多近，根据数据的位置，有几种级别的本地化：
+ PROCESS_LOCAL: 数据和代码在同一个JVM中，最好
+ NODE_LOCAL: 数据在同一个节点上，比如所在相同节点的HDFS上，或者在相同节点的另一个executor上。比PROCESS_LOCAL慢一点，因为数据必须在进程之间传递
+ NO_PREF: 从任何地方访问数据都很一样快，没有本地化
+ RACK_LOCAL: 数据位于同一机架上的服务器，阴虚需要通过网络发送数据，通常是单个交换机
+ ANY: 数据在网络其他地方，而且不在同一机架上

Spark一般会将task安排最佳的本地级别，但这并不总是可能的。因为如果所有空闲的executor中都没有未处理的数据，Spark就会切换到低级别的本地化级别

有两个选项：
(a) 等待一个繁忙的CPU空闲下来，然后再同一个机器的数据上启动task
(b) 直接在其他地方启动一个新的task，前提是需要将数据移动过去 

### Summary 