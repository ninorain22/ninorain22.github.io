## Kafka

### 入门

#### 几个概念
1. kafka作为一个集群运行在一个或多个服务器上
2. kafka集群存储的消息是以topic为类别记录的
3. 每个记录(消息)由一个key, 一个value和时间戳构成

#### 4个核心API
+ `Producer API`发布消息到1个或多个topic
+ `Consumer API`订阅1个或多个topic，并处理产生的消息
+ `Stream API`充当一个流处理器，从1个或多个topic消费输入流，并产生一个输出流到1个或多个输出topic, 有效的将输入流转换到输出流
+ `Connector API`允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。比如连接到一个关系型数据库，捕捉表的所有变更内容

#### 基本术语
+ Topic: Kafka将消息种子分门别类，每一类的消息称之为一个主题(Topic)
+ Producer: 发布消息的对象
+ Consumer: 订阅消息并处理发布的消息的对象
+ Broker: 已发布的消息保存在一组服务器中，称之为Kafka集群，集群中每个服务器都是一个代理(Broker), 消费者可以订阅1个或多个主题，并从Broker拉数据，从而消费这些已发布的消息

#### 主题和日志
![avatar](/Users/dongchao/scala/spark/notes/imgs/introduction_anatomy_of_a_topic.png)

对于每个Topic, Kafka集群维护一个分区日志(log),如上图所示。

每一个分区都是一个顺序的、不可变的消息队列，并且可以持续添加，分区中的消息都被分配了一个序列号，称之为偏移量(offset), 每个分区中的偏移量都是唯一的

Kafka集群保持所有的消息直到过期，无论是否被消费。实际上消费者所持有的元数据就是这个偏移量，也就是这个消费者在这个log中的位置。
正常情况下，消费者消费消息的时候，偏移量也线性的增加，但是实际偏移量由消费者控制，一个消费者操作偏移量不会影响到其他消费者的处理。

消费者的增加和减少，对进群或者其他消费者没有影响。

再说到日志中的分区(partition), 有以下几个用途：
1. 当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都受限于主机的文件限制，不过一个topic可以有多个分区。因此可以处理无限量数据
2. 分区可以作为并行处理的单元

#### 分布式
日志的分区(partition)分布在Kafka集群上, 每个服务器在处理数据和请求时，共享这些分区，每个分区都会在已配置的服务器上备份，确保容错

每个分区都有一台server作为`leader`， 0台或者多台server作为`follwers`, `leader`处理一切对分区(partition)的读写请求，
而`follwers`只被动的同步`leader`上的数据，当`leader`宕机，`follwers`中的一台机器会自动成为新的`leader`

#### 生产者
生产者可以将数据发布到所选择的topic中，生产者负责将记录分配到topic的哪一个分区(partition)中，可以使用循环的方式来实现简单的负载均衡，也可以根据key的语义来分区等

#### 消费者
消费者使用一个`消费组`的名称来进行标识。发布到topic中的每条记录都会被分配给订阅`消费组`中的一个消费者实例，
消费者实例可以分布在多个进程或者多个机器上

+ 如果所有的消费者实例都在同一个`消费组`中，消息记录会负载均衡到每一个消费者实例
+ 如果所有的消费者实例在不同的`消费组`中，每条消息记录就会广播到所有的消费者进程

![avatar](/Users/dongchao/scala/spark/notes/imgs/introduction_consumers.png)

这个Kafka集群有2台server, 4个分区(p0~p3)，以及2个消费者组。
一般而言，每个topic都会有一些消费者组，一个消费者组对应一个"逻辑订阅者"。
一个消费组由多个消费者实例组成，便于扩展和容错。
这就是订阅和发布，只不过订阅者是一组消费者而不是单个的进程

在Kafka中实现消费的方式就是将日志中的分区划分到每一个消费者实例上，以便在任何时间，**每个实例都是分区的唯一消费者**。
也就是最多只有partition个消费者在消费。

Kafka只保证分区内的记录是有序的，而不保证主题中不同分区的顺序。每个分区按照key值排序足以满足大多数应用的要求。
如果想要顺序的处理的处理Topic的所有消息，那就为Topic只提供1个分区。

#### Kafka的保证
+ 生产者发送到特定topic partition的消息将按照发送的顺序处理。
+ 消费者中看到的也是此顺序
+ 如果一个Topic配置了复制因子为N，那么可以允许最多N-1个服务器宕机而不丢失任何已经提交的消息


#### Kafka作为消息系统
与传统的消息系统相比如何？

Kafka中消费者组有2个概念：
+ `队列`: 消费组允许将处理过程分发给一组进程(消费组的成员)
+ `发布订阅`: 允许广播消息给多个消费者组

这种模式下，Kafka的每个topic就可以实现扩展处理以及多订阅者模式，而不需要仅仅选择其中一种

Kafka比传统的消息系统具有更强的保序性。
Kafka通过topic的分区(partition)实现并行，
通过指定topic的分区给消费组，因此每个分区仅仅只有消费组里的一个消费者在消费，
因此，Kafka可以提供有序保证和消费者进程的负载均衡。每个partition仅由同一个消费者组中的一个消费者消费。
并且确保消费者是该partition的唯一消费者，按序消费数据。
每个topic有多个分区，则需要对多个消费者做负载均衡。

但是需要注意：**消费者组中的消费者实例数量不能有超过分区的数量，否则多出的消费者一直空等待，不会收到消息**


#### Kafka作为存储系统
Kafka比别的消息系统的优势是它是一个非常高性能的`存储系统`。

写入到Kafka的数据将写到磁盘并复制到集群中容错，并允许生产者等到消息应答，知道完全写入。

可以认为Kafka是一种专用于高性能、低延迟、提交日志存储、复制和传播特殊用途的`分布式文件系统`

#### Kafka作为流处理
在Kafka中，流处理器持续不断的从`输入Topic`获取数据，进行处理，然后生产数据流到`输出Topic`

可以直接使用`producer`和`consumer`API进行简单的处理，对于复杂的转换，使用`stream API`, 实现数据聚合或者`join`


### 配置

#### Broker配置
+ broker.id
+ log.dirs
+ zookeeper.connect

##### 更新Broker配置
从1.1版本开始，一些broker的配置可以在不重启broker的情况下更新。
比如，改变broker id为0的配置(`log.cleaner.threads`):
`bin/kafka-configs.sh --boostrap-server localhost:9092 --entity-type brokers --entity-name 0 --alter --add-config log.cleaner.threads=2`

#### Topic级别设置
与Topic相关的而配置即包含服务器默认值，也包含可选的每个Topic的覆盖配置。
可以在topic创建时设置1个或多个`--config`选项来进行覆盖配置。
```
bin/kafka-topics.sh --boostrap-server localhost:9092 --create --topic my-topic --partition 1 \
    --replication-factor 1 --config max.message.bytes=64000 --config flush.messages=1
```
也可以使用`alter`命令来设置或修改覆盖至
```
bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name my-topic \
    --alter --add-config max.message.bytes=128000
```

#### Producer配置
+ `key.serializer`: 关键字序列化类
+ `value.serializer`: 值序列化类


### 设计

#### 持久化
Kafka高度依赖文件系统来存储和缓存消息。一般认为磁盘是很慢的，但是好的磁盘结构设计可以使其跟网络速度一样快

对磁盘的线性读取，在有些情况下可以比内存的随机访问还要更快



