## Kafka

#### 几个概念
+ kafka作为一个集群运行在一个或多个服务器上
+ kafka集群存储的消息是以topic为类别记录的
+ 每个记录(消息)由一个key, 一个value和时间戳构成

#### 4个核心API
+ `Producer API`发布消息到1个或多个topic
+ `Consumer API`订阅1个或多个topic，并处理产生的消息
+ `Stream API`充当一个流处理器，从1个或多个topic消费输入流，并产生一个输出流到1个或多个输出topic, 有效的将输入流转换到输出流
+ `Connector API`允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。比如连接到一个关系型数据库，捕捉表的所有变更内容

#### 基本术语
+ Broker: Kafka集群包含一个或多个服务器，这种服务器成为broker
+ topic: 每条发布到kafka集群的消息都有一个类别，成为topic, 物理上不同的topic消息分开存储，
逻辑上一个topic的消息虽然保存于一个或多个broker之上，但是对用户透明）
+ partition: partition是物理上的概念，每个topic包含1个或多个partition, 创建topic时可以指定partition数量.
每个partition对应一个文件夹，在该文件夹下存储该partition的数据和索引文件
+ Producer: 发布消息到Kafka Broker的对象
+ Consumer: 每个Consumer属于一个特定的consumer group, 可以指定group, 如果不指定，属于默认Group.
同一个topic的一条消息只能被同一个consumer group内的一个consumer消费，但是多个consumer group可以同时消费这一个消息

#### Kafka架构
一个典型的kafka集群包含若干个producer, 若干个broker, 入肝consumer group，以及一个zookeeper集群。
kafka通过zookeeper管理集群配置，选取leader, 以及在consumer group发生变化时rebalance.
producer使用push模式将消息发布到Broker, consumer使用pull模式从broker订阅并消费消息

#### Topic和Partition
物理上把topic分成一个或多个partition, 每个partition在物理上对应1个文件夹，存储这个partition的所有消息和索引文件。


#### 主题和日志
![avatar](/assets/images/introduction_anatomy_of_a_topic.png)

对于每个Topic, Kafka集群维护一个分区日志(log),如上图所示。

每个日志文件都是log entries序列，每一个lon entry包含1个4字节的整型（值为N），后跟N个字节的消息体，每条消息都有一个当前partition下唯一的64字节的偏移量offset， 
指明了这条消息的起始位置。这个log entries由多个segment组成，每个segment名为该segment第一条消息的offset和".kafka"组成，
另外，还有一个索引文件，标明了每个segment的offset范围。

每一个分区都是一个顺序的、不可变的消息队列，并且可以持续添加，分区中的消息都被分配了一个序列号，称之为偏移量(offset), 每个分区中的偏移量都是唯一的

Kafka集群保持所有的消息直到过期，无论是否被消费。实际上消费者所持有的元数据就是这个偏移量，也就是这个消费者在这个log中的位置。
正常情况下，消费者消费消息的时候，偏移量也线性的增加，但是实际偏移量由消费者控制，一个消费者操作偏移量不会影响到其他消费者的处理。

消费者的增加和减少，对进群或者其他消费者没有影响。

再说到日志中的分区(partition), 有以下几个用途：
1. 当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都受限于主机的文件限制，不过一个topic可以有多个分区。因此可以处理无限量数据
2. 分区可以作为并行处理的单元

#### 分布式
日志的分区(partition)分布在Kafka集群上, 每个服务器在处理数据和请求时，共享这些分区，每个分区都会在已配置的服务器上备份，确保容错

每个分区都有一台server作为`leader`， 0台或者多台server作为`follwers`, `leader`处理一切对分区(partition)的读写请求，
而`follwers`只被动的同步`leader`上的数据，当`leader`宕机，`follwers`中的一台机器会自动成为新的`leader`

每个partition都有唯一的leader, 所有的读写操作都在leader上完成，leader批量从broker上pull数据，一般情况下partition的数量>=broker数量, 
并且所有partition的leader均匀分布在broker上,follower上的日志和其leader上的完全一样。


#### 生产者
生产者可以将数据发布到所选择的topic中，生产者负责将记录分配到topic的哪一个分区(partition)中，可以使用循环的方式来实现简单的负载均衡，也可以根据key的语义来分区等

#### 消费者
消费者使用一个`消费组`的名称来进行标识。发布到topic中的每条记录都会被分配给订阅`消费组`中的一个消费者实例，
消费者实例可以分布在多个进程或者多个机器上

+ 如果所有的消费者实例都在同一个`消费组`中，消息记录会负载均衡到每一个消费者实例
+ 如果所有的消费者实例在不同的`消费组`中，每条消息记录就会广播到所有的消费者进程

![avatar](/assets/images/introduction_consumers.png)

这个Kafka集群有2台server, 4个分区(p0~p3)，以及2个消费者组。
一般而言，每个topic都会有一些消费者组，一个消费者组对应一个"逻辑订阅者"。
一个消费组由多个消费者实例组成，便于扩展和容错。
这就是订阅和发布，只不过订阅者是一组消费者而不是单个的进程

在Kafka中实现消费的方式就是将日志中的分区划分到每一个消费者实例上，以便在任何时间，**每个实例都是分区的唯一消费者**。
也就是最多只有partition个消费者在消费。

Kafka只保证分区内的记录是有序的，而不保证主题中不同分区的顺序。每个分区按照key值排序足以满足大多数应用的要求。
如果想要顺序的处理的处理Topic的所有消息，那就为Topic只提供1个分区。

#### Kafka的保证
+ 生产者发送到特定topic partition的消息将按照发送的顺序处理。
+ 消费者中看到的也是此顺序
+ 如果一个Topic配置了复制因子为N，那么可以允许最多N-1个服务器宕机而不丢失任何已经提交的消息


#### Kafka作为消息系统
与传统的消息系统相比如何？

Kafka中消费者组有2个概念：
+ `队列`: 消费组允许将处理过程分发给一组进程(消费组的成员)
+ `发布订阅`: 允许广播消息给多个消费者组

这种模式下，Kafka的每个topic就可以实现扩展处理以及多订阅者模式，而不需要仅仅选择其中一种

Kafka比传统的消息系统具有更强的保序性。
Kafka通过topic的分区(partition)实现并行，
通过指定topic的分区分配给消费组中的消费者，每个分区仅仅只有消费组里的一个消费者在消费，
因此，Kafka可以提供有序保证和消费者进程的负载均衡。每个partition仅由同一个消费者组中的一个消费者消费。
并且确保消费者是该partition的唯一消费者，按序消费数据。

每个topic有多个分区，保证了多个消费者实例间的负载均衡。

但是需要注意：**消费者组中的消费者实例数量不能有超过分区的数量，否则多出的消费者一直空等待，不会收到消息**


#### Kafka作为存储系统
Kafka比别的消息系统的优势是它是一个非常高性能的`存储系统`。

写入到Kafka的数据将写到磁盘并复制到集群中容错，并允许生产者等到消息应答，直到完全写入。

可以认为Kafka是一种专用于高性能、低延迟、提交日志存储、复制和传播特殊用途的`分布式文件系统`

#### Kafka作为流处理
在Kafka中，流处理器持续不断的从`输入Topic`获取数据，进行处理，然后生产数据流到`输出Topic`

可以直接使用`producer`和`consumer`API进行简单的处理，对于复杂的转换，使用`stream API`, 实现数据聚合或者`join`


## 文档

### 入门
Kafka适用于两大类场景：
1. 构造实时数据流管道，可用在系统或应用之间可靠的获取数据(相当于MQ)
2. 构建实时流式应用程序，对这些流数据进行转换或影响（流处理)


### 4 设计思想

#### 4.2 持久化
Kafka对消息的存储和缓存依赖于文件系统。磁盘的顺序访问在某些情况下比内存的随机访问还要快。

相比于维护尽可能多的内存缓存，并在空间不足的时候将数据刷新到文件系统，我们把这个过程倒过来，所有数据一开始就被写入到文件系统
的持久化日志中，而不用在cache空间不足时刷新到磁盘。实际上，这表明数据被转移到了内核的页缓存中，这些都是在OS中实现的逻辑。

消息系统使用的持久化数据结构通常是和BTREE相关联的消费者队列或其他用于存储消息源数据的通用随机访问数据结构。
虽然BTREE操作的复杂度是O(logN)， 但在磁盘操作中，此时的性能会大打折扣。

所以，持久化队列可以建立在简单的读取和向文件后追加两种操作之上。这样，读操作不会阻塞写操作，读操作之间也不会影响。性能和数据大小完全分离。

#### 4.3 Efficiency
在消除了磁盘访问模式不佳的情况，主要的性能低下原因就只剩下了2个：大量的小型IO操作 & 过多的字节拷贝

小型的IO操作发生在客户端和服务器之间以及服务器自身持久化操作中，为了避免，Kafka协议是建立在一个"消息块"的抽象基础上，
合理将消息分组，使得一个网络请求将多个消息打包成一组，而不是每次发送一条消息。Consumer每次获取多个大型有序的消息块，
并由服务端依次将消息块一次加载到它的日志中。

对于低效率的字节拷贝，在高负载情况下，为了避免，Kafka使用producer、broker和consumer都共享的标准化二进制消息格式，
这样数据块不用修改就可以在它们之间传递。

broker维护的消息日志就是一个文件目录。每个文件由一系列格式相同的写入到磁盘的消息集合组成，这种写入格式被producer和consumer共用。
保持这种通用格式可以对一些很重要的操作进行优化，现在的UnixOS提供了一个高度优化的编码方式，将数据从页缓存转移到socket网络连接中。
在Linux中，利用系统调用`sendfile`可以做到这一点

数据从文件到套接字的常见数据传输路径：
1. OS从磁盘读取数据到内核的页缓存
2. 应用程序读取内核的数据到用户空间的缓冲区
3. 应用程序将数据写回内核空间到套接字缓冲区
4. 操作系统将数据从套接字缓冲区复制到通过网络发送的NIC缓冲区

以上涉及4次复制操作和2次系统调用，非常低效。使用`sendfile`, 可以将数据从页缓存直接发送到网络，避免重新复制数据。

页缓存和`sendfile`的组合，意味着大多数consumer消费时，磁盘上的活动很少，数据将完全由缓存提供。

#### 4.4 The Producer
**负载均衡**
生产者直接发送数据到主分区的服务器上，不需要经过任何中间路由。
为了实现这个功能，所有Kafka服务器节点都应该能响应这样的元数据请求：
+ 哪些服务器是活着的
+ 主题的哪些分区是主分区
+ 分配在哪个服务器上

客户端控制消息发送数据到哪个分区，可以实现随机的负载均衡方式，或者使用一些特定语义的分区函数。

**异步发送**

#### 4.5 消费者
consumer通过向broker发出一个fetch请求来获取它想要消费的partition。
consumer的每个请求都在log中指定了对应的offset,并接收从该位置开始的一大块数据。

**消费者的位置**
Kafka处理消息丢失的问题：Kafka的topic被分割成了一组完全有序的partition, 其中每一个partition在任意给定时间内，
只能被每个订阅了这个topic的消费组的**1个**消费者消费。
这意味着partition中的每一个消费者的位置仅仅是一个数字，即下一条需要消费的消息的偏移量。
这样被消费的消息的状态信息相当少，每个partition只需要一个数字，这个状态信息还可以作为周期性的检查点。

这样做还有一个好处，消费者可以回退到之前的偏移量来再次消费之前的数据。

#### 4.6 消息交付语义
Kafka在Kafka Streaming中支持了exactly-once的消息交付功能，并且在topic之间传递数据和处理时，使用事务型producer/consumer提供exactly-once交付功能。








