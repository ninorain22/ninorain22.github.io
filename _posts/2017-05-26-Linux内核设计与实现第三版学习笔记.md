## 1.4 Linux内核和传统Unix内核的比较

+ Linux支持动态加载内核模块
+ Linux支持对称多处理（SMP）机制
+ Linux内核可以抢占。Linux内核允许在内核运行的任务优先执行
+ Linux内核并不区分线程和一般进程
+ Linux提供具有设备类的面向对象的设备模型、热插拔时间，以及用户空间的设备文件系统(sysfs)
+ Linux忽略了STEAMS等特性

### 2.4.6 同步和并发
内核容易产生竞争条件，因此内核许多特性都要求能够并发访问共享数据，特别是：
+ Linux是抢占多任务操作系统。内核的进程调度即兴对进程进行调度和重新调度。内核必须和这些任务同步
+ Linux内核支持对称多处理系统（SMP），因此在两个以上处理器上执行的内核代码很可能会同时访问一个共享资源
+ 中断处理程序有可能访问同一资源
+ Linux内核可以抢占

常见解决竞争的办法是**自旋锁**和**信号量**


# 进程管理

## 3.1 进程
在Linux中，进程通常是fork()的结果，该系统调用复制一个现有进程来创建另一个进程

## 3.2 进程描述符及任务结构
内核把进程的列表存放在任务队列的**双向循环链表**中。链表的每一项都是类型为``task_struct``的进程描述符结构

### 3.2.1 分配进程描述符
Linux通过slab分配器分配``task_struct``结构。

### 3.2.2 进程描述符的存放
内核通过一个唯一的进程标识值或PID来标识每个进程。PID是一个数，表示为``pid_t``隐含类型，实际上是一个``int``类型

### 3.2.3 进程状态
系统中每个进程必然处于下面5种状态之一：
+ TASK_RUNNING(运行)：进程是可执行的，或者正在执行，或在运行队列种等待执行。这是进程在用户空间中执行的唯一可能的状态；这种状态也可以应用到内核空间中正在执行的进程
+ TASK_INTERRUPTIBLE(可中断)：进程正在睡眠(被阻塞), 等待某些条件的达成
+ TASK_UNINTERRUPTIBLE（不可中断)：这个状态通常在进程必须等待时不受干扰或等待时间很快就会发生时出现，使用较少
+ __TASK_TRACED: 被其他进程跟踪的进程
+ __TASK_STOPPED(停止)：进程停止执行


## 3.3 进程创建
Unix进程创建：
+ ``fork()``: 拷贝当前进程创建一个子进程
+ ``exec()``: 负责读取可执行文件并将其载入地址空间开始运行

### 3.3.1 写时拷贝
传统``fork()``系统调用直接把所有资源复制给新创建的进程。过于简单，效率地下。如果新进程打算立即执行一个新的映像，那么所有拷贝都会失效。
Linux的``fork()``使用**写时拷贝**页实现：内核并不复制整个进程地址空间，只有在需要写入时，数据才会被复制

### 3.3.3 fork()
Linux通过``clone()``系统调用实现``fork()``, ``fork()``、``vfork()``和``__clone()``都根据需要的参数标志区调用``clone()``,然后由``clone()``去调用``do_fork()``
``do_fork``调用``copy_process()``函数，然后让进程开始运行，``copy_process()``函数流程如下：
1. 调用``dup_task_struct()``为新进程创建一个内核栈、thread_info结构和task_struct，这些值与当前进程的值相同
2. 检查并确保新创建这个子进程后，当前用户所有的进程数没有超出给它分配的资源限制
3. 进程描述符内的非继承而来的成员都要被清0或者初始化。``task_struct``的大多数数据依然未被修改
4. 子进程状态被设置为TASK_UNINTERRUPTIBLE,已保证它不会投入运行
5. ``copy_process()``调用``copy_flags()``以更新换代``task_struct``的``flags``成员。
6. 调用``alloc_pid()``为进程分配一个有效的PID
7. 根据传递给``clone()``的参数标志，``copy_process()``拷贝或共享打开的文件、文件系统信息、信号处理函数、进程地址空间和命名空间等
8. 扫尾工作并返回一个只想子进程的指针


## 3.4 线程在Linux中的实现
线程被是为一个与其他进程共享某些资源的进程。

### 3.4.1 创建线程
和创建普通进程类似，只是在``clone()``传递参数指明需要共享的资源
```
    clone(CLONE_VM | CLINE_FS | CLONE_FILES | CLONE_SIGHAND, 0)
```
和``fork()``差不多，只是父子共享地址空间、文件资源系统、文件描述符和信号处理程序

### 3.4.2 内核线程
一种独立运行在内核空间的标准进程。内核线程和普通线程的区别在于内核线程没有独立的地址空间，它们只在内核空间运行，从来不切换到用户空间去。可以被调度，也可以被抢占

## 3.5 进程终结
大部分要靠``do_exit()``来完成：
+ 将task_struct中的标志成员设置为PF_EXITING
+ 调用del_timer_sync()删除任一内核定时器，根据返回的结果，确保没有定时器在排队，也没有定时器处理程序在运行
+ 如果BSD的进程记账功能是开启的，do_exit()调用acct_update_integrals()来输出记账信息
+ 调用exit_mm()来释放占用的mm_struct
+ 调用sem__exit()。如果进程排队等候IPC信号，则离开队列
+ 调用exit_files()和exit_fs(),以分别递减文件描述符、文件系统数据的引用计数
+ 接着把存放在task_struct的exit_code成员中的任务推出代码置为由exit()提供的退出代码
+ 调用exit_notify()向父进程发起信号，给子进程重新找养父，养父为线程组中的其他线程或者init进程，并把进程状态设置为EXIT_ZOMBIE
+ 调用schedule()切换到新的进程

### 3.5.1 删除进程描述符
在调用了do_exit()之后，尽管进程已经不能再运行，但系统保留了它的进程描述符。这样可以让系统有办法在子进程终结后仍能获取得它的信息
在父进程获得已终结的子进程的信息后，或者通知内核它不再关注那些信息之后，子进程的task_struct才会被释放


# 进程调度

## 4.1 多任务
多任务系统可以划分为两类：非抢占式多任务和抢占式多任务

## 4.2 Linux的进程调度
2.6版本中采用反转楼梯最后期限调度算法（RSDL）(CFS)

## 4.3 策略
### 4.3.1 I／O消耗型和处理器消耗型的进程
调度策略在两个矛盾的目标寻找平衡
+ 进程响应迅速
+ 最大系统利用率

### 4.3.2 进程优先级
Linux采用了2种不同的优先级范围。第一种是nice值。-20 ～ +19，nice值越大优先级越低
第二种是实时优先级。其值可以配置 0 ～ 99，越高代表优先级越高

### 4.3.3 时间片
表明进程在被抢占前所能持续运行的时间
Linux系统是抢占式的。其抢占时机取决于新的可运行程序消耗了多少处理器使用比。如果消耗的使用比比当前进程小，则新进程立即投入运行，抢占当前进程，否则推迟

## 4.4 Linux调度算法
### 4.4.1 调度器类
允许多种不同的可动态添加的调度算法并存，调度属于自己范畴的进程。每个调度器有一个优先级。基础调度器会按照优先级顺序遍历调度类。
完全公平调度（CFS）是一个针对普通进程的调度类

### 4.4.2 Unix系统中的进程调度
CFS采用的是分配进程一个处理器使用比重，通过这种方式保证调度程序恒定的公平性

### 4.4.3 公平调度
CFS允许每个进程运行一段时间、循环轮转、选择运行最少的进程作为下一个运行进程,不再采用分配给每个进程时间片

## 4.5 Linux调度的实现
+ 时间记账
+ 进程选择
+ 调度器入口
+ 睡眠和唤醒

### 4.5.1 时间记账


# 中断和中断处理

## 7.1 中断
异常与中断不同，它在产生时必须考虑与处理器时钟同步。实际上，异常也被成为同步中断

## 7.2 中断处理程序
中断程序必须按照特定的类型声明，以便内核以标准的方式处理传递程序的信息。中断处理程序与其他内核函数的区别在于**中断处理程序是被内核调用来响应中断的**
他们运行在中断上下文中，也称为原子上下文

## 7.3 上半部与下半部的对比
以网卡为例，当网卡接收来自网络的数据包时，需要通知内核数据包到来。网卡需要立即完成这件事，因此，网卡立即发出中断，通知硬件，拷贝最新的网络数据包到内存。然后读取网卡更多的数据包
当网络数据包被拷贝到系统内存后，中断任务就算完成，这时它将控制权交还给系统被中断前原先运行的程序

## 7.4 注册中断处理程序
每一设备都有相关的驱动程序，如果设备需要使用中断（大部分），那么相应的驱动程序就注册一个中断处理程序


# 内核同步介绍

## 9.1 临界区和竞争条件
临界区就是访问和操作共享数据的代码段

## 9.2 加锁
Linux自身实现了几种不通锁机制，各种锁机制区别主要在于：当锁已经被其他线程持有，因而不可用时的行为表现

### 9.2.1 造成并发执行的原因
用户空间之所以需要同步，是因为用户程序会被调度程序抢占和重新调度。
内核中有类似可能造成并发执行的原因：
+ 中断
+ 软中断和tasklet
+ 内核抢占
+ 睡眠以及用户空间的同步
+ 对称多处理器

### 9.2.2 了解要保护什么
大多数内核数据结构都需要加锁。
如果有其他执行线程可以访问这些数据，那么就给这些数据加上某种形式的锁；
如果任何其他什么东西都能看到它，那么就要加锁；
要给数据加锁，而不是给代码加锁

## 9.3 死锁
死锁产生的条件：一个或多个执行线程和一个或多个资源，每个线程都在等待其中的一个资源，但是所有的资源都被占用来，且不会释放已占有的资源，于是任何线程都无法继续，这就是死锁

如果两个或多个锁曾在同一时间被请求，那么以后其他函数请求它们也必须按照当前的加锁顺序进行

## 9.4 争用和扩展性


# 10 内核同步方法

## 10.1 原子操作
内核提供了两组原子操作接口
+ 一组针对整数进行操作
+ 一组针对单独的位进行操作

## 10.2 自旋锁
### 10.2.1 自旋锁方法
自旋锁在同一时刻最多被一个执行线程持有，所以同一时刻最多只有一个线程位于临界区
自旋锁可以使用在中断处理程序中。在获取锁之前，首先要禁止本地中断（当前处理器上的中断请求），否则，中断处理程序会打断正持有锁的内核代码，可能会试图争用这个已经被持有的自旋锁

## 10.3 读-写自旋锁
适用于某个数据结构的操作可以被划分为读／写或者消费者／生产者两种类别时

如果加锁时间不长且代码不会睡眠（例如中断处理程序），使用自旋锁是最佳选择，但是加锁时间长或者代码可能睡眠，那么最好用**信号量**来完成加锁

## 10.4 信号量
Linux中的信号量是一种睡眠锁，如果有一个任务试图获取一个已被占用的信号量时，信号量会将其推进一个等待队列，然后让其睡眠。处理器此时转去处理其他请求

### 10.4.1 计数信号量和二值信号量
在使用信号量时，基本用到的都是互斥信号量（计数=1的信号量）
down()操作对信号量计数-1来获取一个信号量
在临界区中的操作完成后，up()来释放信号量，来增加信号量的计数值

## 10.5 读-写信号量
所有读-写信号量都是互斥信号量（引用计数为1）

## 10.6 互斥体mutex
+ 任何时刻只有一个任务可以持有mutex,mutex计数永远是1
+ 给mutex上锁者必须负责再给其解锁，不能在一个上下文中锁定一个mutex，而在另一个上下文给其解锁
+ 不允许递归的上锁和解锁
+ 当持有一个mutex时，进程不可退出
+ mutex不能在中断或者下半部中使用
+ mutex只能通过官方API管理

## 10.7 完成变量

## 10.8 BLK:大内核锁
全局自旋锁，为了方便从Linux最初的SMP过度到细粒度加锁机制

## 10.9 顺序锁
seq锁。
依靠一个序列计数器，当有疑义的数据被写入时，会得到一个锁，并且序列值增加。在读取数据之前和之后，都会读取序号。如果读取的序号相同，那么说明在读操作过程中没有被写操作打断
此外，如果读取的值锁偶数，就表明没有写操作发生
适用场景：
+ 数据存在很多读者
+ 写者很少
+ 写优先于读，而且不允许读者让写这饥饿
+ 数据结构简单

## 10.10 禁止抢占

## 10.11 顺序和屏障
确保顺序的执行称为屏障(barriers)

## 10.12 小结
最简单的确保同步的方法--原子操作
自旋锁--内核中最普通的锁，它提供了轻量级单独持有者的锁，即争用时忙等
信号量--一种睡眠锁
mutex--更通用的衍生锁


# 定时器和时间管理
内核需要相对时间和绝对时间
周期性时间的产生，都是由系统定时器驱动的

## 11.1 内核中的时间概念
系统定时器以某种频率自行触发时钟中断，该频率可以通过编程预定，称作**节拍率**

连续两次时钟中断的间隔时间，称为**节拍**

## 11.2 节拍率：HZ
X86体系结构中，系统定时器频率默认为100，因此X86时钟中断频率为100HZ，即每秒中断100次
大多数体系结构的节拍率是可以调的

### 11.2.1 理想的HZ值
Linux 2.5开发版内核的中断频率提高到1000HZ。
提高节拍率等同于提高中断解析度，如果HZ=100的时钟执行粒度为10ms, 即系统中周期事件最快为每10ms运行一次。当HZ=1000时，执行粒度就为1ms
另外，提高解析度的同时也提高了准确度，比如内核在某个随机时刻触发定时器，而它可能在任何时间超时，但由于只有在时钟中断到来才能执行，因粗平均误差为半个时钟

### 11.2.2 高HZ的优势
+ 内核定时器频度和精准度更高
+ 依赖定时值执行的系统调用, 比如poll()和select()，能以更高的精度运行
+ 对资源消耗和系统运行时间的测量更精细
+ 提高进程抢占的准确度

### 11.2.3 高HZ的劣势
+ 时钟中断频率高，系统负担月中，必须花更多时间来处理时钟中断程序
现代计算机上，1000HZ不会对系统性能造成较大的影响

## 11.3 jiffies
全局变量jiffies用来记录系统自启动以来产生的节拍的总数
内核给jiffies附一个特殊的初值，引起这个变量不断的溢出，由此捕捉bug。当找到实际的jiffies后，就首先把这个偏差减去

### 11.3.1 jiffies的内部表示
jiffies总是无符号长整数（unsigned long)

```
volatile关键字：volatile关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改
volatile关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。
volatile 指出 i是随时可能发生变化的，每次使用它的时候必须从i的地址中读取，因而编译器生成的汇编代码会重新从i的地址读取数据放在b中。而优化做法是，由于编译器发现两次从i读数据的代码之间的代码没有对i进行过操作，它会自动把上次读的数据放在b中。而不是重新从i里面读。这样以来，如果i是一个寄存器变量或者表示一个端口数据就容易出错，所以说volatile可以保证对特殊地址的稳定访问
```
### 11.3.2 jiffies的回绕
节拍计数增加到最大值2的31次方-1，它的值会回绕到0
内核提供了四个宏来帮助比较节拍计数，他们能正确的处理节拍计数回绕清空
time_after()    
time_before()
time_after_eq() 
time_before_eq()

## 11.4 硬时钟和定时器
体系结构提供了两种设备进行计时
1. 系统定时器
2. 实时时钟

### 11.4.1 实时时钟
用来持久存放系统时间的设备
系统启东市，内核读取RTC来初始化墙上时间，该时间存放在xtime变量中。

### 11.4.2 系统定时器
周期性触发中断机制（可能是电子晶振，可能是衰减测量器）
在x86体系结构中，主要采用可编程中断时钟（PIT）

## 11.5 时钟中断处理程序
划分为2部分：**体系结构相关部分**和**体系结构无关部分**

与体系结构相关的例程作为系统定时器的中断处理程序注册到内核中，完成以下操作：
+ 获取xtime_lock锁，对访问jiffies_64和墙上时间xtime进行保护
+ 需要时应答或重新设置时钟
+ 周期性地使用墙上时间更新时钟
+ 调用体系机构无关的时钟例程

## 11.7 定时器
内核定时器可以用来将部分代码推迟到下半部执行
```
struct timer_list {
    struct list_head entry;     // 定时器链表入口
    unsigned long expires;      // 以jiffies为单位的定时值
    void (*function) (unsigned long);    // 定时器处理函数
    unsigned long data;         // 传给处理函数的长整形参数
    struct tvec_t_base_s *base;     // 定时器内部值
}
```

使用
```
// 创建
struct timer_list my_timer;
// 初始化
init_timer(&my_timer);
// 填充值
my_timer.expires = jiffies + delay; // 超时节拍数
my_timer.data = 0;
my_timer.function = my_function;
// 激活
add_timer(&my_timer);
```

### 11.7.2 定时器竞争条件
一般情况下，应该使用del_time_sync()来取代del_timer()函数，因为无法确定在删除定时器时，它是否还正在其他处理器上运行

### 11.7.3 实现定时器
定时器作为软中断在下半部上下文中执行，具体来说，时钟中断处理程序会执行update_process_time()函数，该函数随机调用run_local_timers()
```
void run_local_timers(void)
{
    hrtimer_run_queues();
    raise_softirq(TIMER_SOFTIRQ); // 执行定时器软中断
    softlockup_tick();
}
```

## 11.8 延迟执行
内核代码，尤其是驱动程序，除了使用定时器或者下半部机制意外，还需要其他其他方法来推迟执行任务。比如重新设置网卡的以太模式需要2ms，所以驱动程序必须至少等待2ms才能继续运行

### 11.8.1 忙等待
仅适用于延迟的时间是节拍的整数倍，或者精确率要求不高
几乎不用

更好的方法是代码等待时，允许内核重新调度执行其他任务
```
unsigned long delay = jiffies + 5*HZ;
while (time_before(jiffies, delay))
    cond_resched(); // 将调度一个新程序投入运行
```
因为cond_resched()需要调用调度程序，因此它不能在中断上下文中使用——只能在进程上下文中使用
jiffies字段被标记为volatile，指示编译器每次访问变量时都重新从主内存中获得，而不是直接访问寄存器中的变量名

### 11.8.2 短延迟
有的代码要求延迟时间短，而且要求延迟时间很精确
内核提供了3个可以处理ms,us级别的延迟函数
```
void udelay(unsigned long usecs);
void ndelay(unsigned long nsecs);
void mdelay(unsigned long msecs);
```

BogoMIPS:
MIPS(每秒处理百万条指令)
BogoMIPS记录处理器在给定时间内忙循环执行的次数


### 11.8.3 schedule_timeout()
更理想的延迟执行方法是schedule_timeout()函数
该方法会让需要延迟执行的任务睡眠到指定的延迟时间后再重新运行
```
set_current_state(TASK_INTERRUPTIBLE);
schedule_timeout(s*HZ); // s秒后唤醒
```

由于schedule_timeout()需要调用调度程序，所以调用它的代码必须保证能够睡眠。因此调用代码必须处于进程上下文中，且不能持有锁
```
signed long schedule_timeout(signed long timeout)
{
    timer_t timer;
    unsigned long expire;
    
    switch (timeout) {
        case MAX_SCHEDULE_TIMEOUT: 
            schedule();
            goto out;
        default:
            if (timeout < 0) {
                printk(KERN_ERR "***");
                current->state = TASK_RUNNING;
                goto out;
            }
    }
    
    expire = timeout + jiffies;
    
    init_timer(&timer);
    timer.expires = expire;
    timer.data = (unsigned long) current;
    timer.function = process_timeout;
    
    add_timer(&timer);
    schedule();
    del_timer_sync(&timer);
    
    timeout = expire - jiffies;
    
    out:
        return timeout < 0 ? 0 : timeout;
}
```
定时器超时，process_timeout()会调用
```
void process_timeout(unsigned long data)
{
    wake_up_process((task_t *) data);
}
```
该函数将任务设置为TASK_RUNNING状态，然后放入运行队列


# 内存管理

## 12.1 页
内存管理单元（MMU）把物理页作为内存管理的基本单位，也是从虚拟内存角度来看的最小单位
内核用struct page结构表示系统中的每个物理页
```
struct page {
    unsigned long flags;        // 页的状态，是不是脏的，是不是被锁定在内存中，每一位单独表示一种状态
    atomic_t _count;            // 页的引用计数
    atomic_t _mapcount;
    unsigned long private;
    struct address_space *mapping;
    pgoff_t index;
    struct list_head lru;
    void *virtual;              // 页的虚拟地址，通常情况下，有些内存并不永久地映射到内核空间上，这时，该值为NULL
}
```

## 12.2 区
有些页位于内存中特定的物理地址上，所以不能用于一些特定的任务。所以内核把页划分为不同的区
内核对具有相似特性的页分组。Linux必须处理如下两种硬件存在缺陷而引起的内存熏制问题
+ 一些硬件只能用某些特性的内存地址来执行DMA（直接内存访问）
+ 一些体系结构的内存的物理殉职范围比虚拟寻址范围大得多，因此有些内存不能永久映射到内核空间上

Linux主要使用了4种区：
1. ZONE_DMA - 这个区包含的页只能用来执行DMA操作
2. ZONE_DMA32 - 和ZONE_DMA类似，只是这些页面只能被32位设备访问
3. ZONE_NORMAL - 能正常映射的页
4. ZONE_HIGHEM - 包含*高端内存*，其中的页并不能永久地映射到内核地址空间
在32位x86系统上，ZONE_HIGHEM为高于896MB的所有物理内存。在其他体系结构上，由于所有内存都被直接映射，所以ZONE_HIGHEM为空
每个区都用struct zone表示
```
struct zone {
    unsigned long               waternark[NR_WMARK];            // 持有该区的最小值、最低和最高水位值，该水位随着空闲内存的多少而变化
    unsigned long               lowmen_reserve[MAX_NR_ZONES];
    struct per_cpu_pageset      pageset[NR_CPUS];
    spinlock_t                  lock;                           // 自旋锁，防止该结构被并发访问
    struct free_area            free_area[MAX_ORDER];
    spinlock_t                  lru_lock;
    struct zone_lru {
        struct list_head list;
        unsigned long nr_saved_scan;
    } lru[NR_LRU_LISTS];
    struct zone_recliam_stat    reclaim_stat;
    unsigned long               pages_sacnned;
    unsigned long               flags;
    atoimic_long_t              vm_stat[NR_VM_ZONE_STAT_ITEMS];
    int                         prev_priority;
    unsigned int                inactive_ratio;
    wait_queue_head_t           *wait_table;
    unsigned long               wait_table_hash_nr_entries;
    unsigned long               wait_table_bits;
    struct pglist_data          *zone_pgdat;
    unsigned long               zone_start_pfn;
    unsigned long               spanned_pages;
    unsigned long               present_pages;
    const char                  *name;                        // 'DMA'|'Normal'|'HignMem' 
}
```

## 12.3 获得页
``struct page * alloc_pages(gfp_t gfp_mask, unsigned int order)``
该函数分配2的order次方个连续的物理页，并返回一个指向第一个页page结构体的指针
可以用这个函数把给定的页转换成它的逻辑地址：
``void * page_address(struct page *page)``
可以调用这个函数来获得页：
``unsigned long __get_free_pages(gfp_t gfp_mask, unsigned long order)``
它直接返回第一个页的逻辑地址

如果只需要一页, order参数可以不传

### 12.3.2 释放页
```
void __fres_pages(struct page * page, unsigned int order);
void free_pages(unsigned long addr, unsigned int order);
void free_pages(unsigned long addr);
```

## 12.4 kmalloc()
用于获得以字节为单位的一块内核内存``void * kmalloc(size_t size, gfp_t flags);``
返回一个指向内存块的指针

### 12.4.1 gfp_mask标志
分为3类：
1. 行为修饰符：表示内核应当如何分配所需内存，例如中断处理程序要求内核在分配内存过程中不能睡眠
2. 区修饰符：指明到底从这些区中的哪一区进行分配
3. 类型：组合了行为修饰符和区修饰符，例如GFP_KERNEL（也是首选标示）

GFP_KERNEL可能会引起睡眠，因为它使用的是普通优先级。
GFP_ATOMIC标示不能睡眠的内存分配，适用于中断处理程序、软中断和tasklet等不能睡眠的情况）

### 12.4.2 kfree()
``void kfree(const void *ptr);``
释放由kmalloc()分配出来的内存块


## 12.5 vmalloc()
类似于kmalloc()，只是vmalloc()分配的内存虚拟地址是连续的，而物理地址则无须连续。而kmalloc()确保返回的页在物理地址上都是连续的
相比于kmalloc()，vmalloc()为了把物理上不连续的页转换为虚拟地址连续的页，必须专门建立页表想。这回导致比直接内存映射大得多的TLB（硬缓冲区，缓存虚拟地址到物理地址的映射关系）抖动
``void * vmalloc(unsigned long size);``
释放：``void vfree(consty void *attr);``，这个函数可以睡眠，因此不能从中断上下文中调用

## 12.6 slab层
slab分配器就是一种通用数据结构缓存层

### 12.6.1 slab层的设计
slab层把不同的对象划分为高速缓存组，每个组都存放不同类型的对象，每种对象类型对应一个高速缓存
然后，这些高速缓存又被划分为slab。slab由一个或者多个物理上连续的页组成。一般情况，slab仅由一页组成
每个slab处于三种状态之一：满、部分满、空
当内核需要一个新对象时，优先从部分满的slab中进行分配

slab描述符：
```
struct slab {
    struct list_head list;      // 满、部分满或空链表
    unsigned long colouroff;    // slab着色的偏移量
    void $s_mem;                // 在slab中的第一个对象
    unsigned int inuse;         // slab中已经分配的对象数
    kmem_bufctl_t free;         // 第一个空闲对象
}
```
slab层的关键就是避免频繁分配和释放页：
只有在给定的高速缓存部分中既没有满、也没有空的slab时才会调用页分配函数；
只有在内存变得紧缺时，系统试图释放出更多内存以供使用，或者当高速缓存显示的被撤销时，才会调用释放函数

### 12.6.2 slab分配器的接口
一个新的高速缓存通过以下函数创建
```
struct kmem_cache * kmem_cache_create(const char *name,         // 高速缓存的名字
                                      size_t size,              // 缓存中每个元素的大小
                                      size_t align,             // slab内第一个对象的偏移，来确保页内进行特定的对齐  
                                      unsigned long flags,      // 控制高速缓存的行为，0表示没有特殊行为
                                      void (*ctor)(void *));
```

从缓存中分配：
``void * kmem_cache_alloc(struct kmem_cache *cachep, gfp_t flags);``
从高速缓存cachep中返回一个指向对象的指针。如果高速缓存所有的slab中都没有空闲的对象，那么slab层必须通过kmem_getpages()获取新的页
释放对象：
``void kmem_cache_free(struct kmem_cache *cachep, void *objp);``
把cachep中的对象objp标记为空闲
slab层负责内存紧缺情况下所有底层的对齐、着色、分配、释放和回收等
如果要频繁创建很多相同类型的对象，那么应该考虑使用slab高速缓存

## 12.7 在栈上的静态分配
内核栈小且固定。给每个进程分配一个固定大小的小栈后，不但可以减少内存的消耗，而且内核也无须负担栈管理任务

## 12.8 高端内存的映射
通过alloc_pages()，以__GFP_HIGHMEM标志获得的页不可能有逻辑地址

### 12.8.1 永久映射
要映射一个给定的PAGE结构到内核地址空间，可以使用``void *kmap(struct page *page)``
这个函数在高端内存或低端内存上都可以使用
1. 如果page结构对应的是低端内存中的一页，函数只会单纯的返回该页的虚拟地址
2. 如果是位于高端内存，则会建立一个永久映射，再返回该地址
该函数可以睡眠，因此只能用在进程上下文中
对应解除映射``void kunmap(struct page * page)``

### 12.8.2 临时映射
在不能睡眠不能阻塞的中断处理程序上下文中，内核可以原子的把高端内存中的一个页映射到某个保留的映射中
``void kmap_atomic(struct page *page, enum km_type type)``
对应解除映射``void kunmap_atomic(void *kvaddr, enum km_type type)``,也不会阻塞

## 12.9 每个CPU的分配
```
unsigned long my_percpu[NR_CPUS];

int cpu;
cpu = get_cpu();    // 获取当前处理器，并禁止内核抢占
my_percpu[cpu]++    // 一些操作
put_cpu();          // 激活内核抢占
```

## 12.10 新的每个CPU接口

### 12.10.1 编译时的每个CPU数据
```
get_cpu_var(name)++;        // 增加该CPU上的NAME变量的值
put_cpu_var(name);          // 完成，重新激活内核抢占

per_cpu(name, cpu)++;       // 增加制定处理器上NAME变量的值。但是不会禁止内核抢占，也不会提供任何锁保护
```

### 12.10.2 运行时的每个CPU数据
```
void *alloc_percpu(type);       // 一个宏
void *__alloc_percpu(size_t size, size_t align);
void free_percpu(const void *);
```

## 12.11 使用每个CPU数据的原因
1. 减少了数据锁定。按照每个CPU访问数据的逻辑，就不需要任何锁
2. 大大减少缓存失效

## 12.12 分配函数的选择
1. 需要连续的物理页 - 低级页分配器／kmalloc()
2. 从高端内存分配 - alloc_pages()
3. 不需要物理上连续的页，仅需要虚拟地址上连续的页 - vmalloc()
4. 要创建和撤销很多大的数据结构 - slab高速缓存


# 虚拟文件系统VFS
``ret = write(fd, buf, len);``
用将buf指针指向的长度为len字节的数据写入fd对应的文件的当前位置

## 13.3 Unix文件系统
4中传统抽象概念：文件，目录项，索引节点和安装点

Unix将文件的相关信息和文件本身区分
文件相关信息（元数据），存储在一个单独的数据结构中，即索引节点。
在磁盘上，文件信息按照索引节点的形式存放在单独的块中；控制信息存储在磁盘的超级块中

## 13.4 VFS对象及其数据结构
4个主要的对象类型
1. 超级块对象 - 代表一个具体的已安装文件系统 - 包括内核针对特定文件系统所能调用的方法，如write_inode()和sync_fs()
2. 索引节点对象 - 代表一个具体的问题 - 包括内核针对特定文件所能调用的方法，如create()和link()
3. 目录项对象 - 代表一个目录项 - 包括内核针对特定目录所能调用的方法，如d_compare()和d_delete()
4. 文件对象 - 代表由进程打开的文件 - 包括进程针对一打开文件的所能调用的方法，如read()和write()

## 13.5 超级块对象
各种文件系统都必须实现，用于存储特定文件系统的信息。对应于存放在磁盘特定扇区中的文件系统超级块或者文件系统控制块
```
struct super_block {
    struct list_heade           s_list;                         // 指向所有超级块的链表
    dev_t                       s_dev;                          // 设备标识符
    unsigned long               s_blocksize;                    // 以字节为单位的块大小
    
    unsigned char               s_blocksize_bits;               // 以位为单位的块大小
    unsigned char               s_dirt;                         // 修改标志
    unsigned long long          s_maxbytes;                     // 文件大小上限
    struct file_system_type     s_type;                         // 文件系统类型
    struct super_operations     s_op;                           // 超级块方法
    strcut dquot_operations     *dp_op;                         // 磁盘限额方法    
    struct quotactl_ops         *s_qcop;                        // 限额控制方法
    struct export_operations    *s_export_op;                   // 导出方法
    unsigned long               s_flags;                        // 挂载标志
    unsigned long               s_magic;                        // 文件系统的幻数    
    struct dentry               *s_root;                        // 目录挂载点
    struct rw_semaphore         s_umount;                       // 卸载信号量
    struct semaphore            s_lock;                         // 超级块信号量
    int                         s_count;                        // 超级块引用计数
    int                         s_need_sync;                    // 尚未同步标志
    atomic_t                    s_active;                       // 活动引用计数
    void                        *s_security;                    // 安全模块
    struct xattr_handler        **s_xattr;                      // 扩展的属性操作
    struct list_head            s_inodes;                       // inodes链表
    struct list_head            s_dirty;                        // 脏数据链表
    struct list_head            s_io;                           // 回写链表
    struct list_head            s_more_io;                      // 更多的回写链表
    struct hlist_head           s_anon;                         // 匿名目录项
    struct list_head            s_files;                        // 被分配文件链表
    struct list_head            s_dentry_lru;                   // 未被使用目录项链表
    int                         s_nr_dentry_unused;             // 链表中目录项的数目
    struct block_device         *s_bdev;                        // 相关块设备
    struct mtd_info             *s_mtd;                         // 存储磁盘信息
    struct list_head            s_instance;                     // 该类型文件系统
    struct quota_info           s_dquot;                        // 限额相关选项
    int                         s_frozen;                       // frozen标志位
    wait_queue_head_t           s_wait_unfrozen;                // 冻结的等待队列
    char                        s_id[32];                       // 文本名字
    void                        *s_fs_info;                     // 文件系统特殊信息
    fmode_t                     s_mode;                         // 安装权限
    struct semaphore            s_vfs_rename_sem;               // 重命名信号量
    u32                         s_time_gran;                    // 时间戳粒度
    char                        *s_subtype;                     // 子类型名称
    char                        *s_options;                     // 已存安装选项
```

## 13.6 超级块操作
s_op指向超级块的操作函数表，由super_operations结构体表示，每一项都是指向一个超级块操作函数的指针。

## 13.7 索引节点对象
索引节点对象包含了内核在操作文件或目录时需要的全部信息

## 13.9 目录项对象
VFS把目录当作文件对待，但解析一个路径并遍历其分量比较复杂。因此，VFS引入了目录项对象
VFS在执行目录操作时，会现场创建目录项对象

### 13.9.1 目录项状态
1. 被使用：对应一个有效的索引节点，并且表明该对象存在一个或者多个使用者。
2. 未被使用：对应一个有效的索引节点，但是当前VFS并未使用它。该目录项对象仍然执行一个有效对象，被保留在缓存中以便需要时再次使用。
3. 负状态：没有对应的有效索引节点。但是目录项仍然保留，以便快速解析以后的路径查询

### 13.9.2 目录项缓存
内核将目录项对象缓存在目录项缓存（dcache)，包括
+ 被使用的目录项链表
+ 最近被使用的双向链表：还有未被使用的和负状态的目录项对象
+ 散列表和响应的散列函数来快速的将给定路径解析为相关目录项对象
dcache也在一定意义上提供对索引节点的缓存，也就是icache。和目录项对象相关的索引节点对象不会被释放

## 13.11 文件对象
文件对象表示进程已经打开的文件。由相应的open()系统调用创建，由close()系统调用撤销

## 13.13 和文件系统相关的数据结构
+ file_system_type: 用来描述各种特定文件系统类型，比如ext3, ext4或UDF
+ vfsmount:描述一个安装文件系统的实力

## 13.14 和进程相关的数据结构
每个进程都有自己的一组打开的文件，有3个数据结构将VFS和系统进程联系一起：
+ file_struct
+ fs_struct
+ namespace
```
struct file_struct {
    atomic_t            count;        // 结构的使用计数
    struct fdtable      *fdt;         // 指向其他fd表的指针
    struct fdtable      fdtab;        // 基fd表
    spinlock_t          file_lock;    // 单个文件的锁
    int                 next_fd;      // 缓存下一个可用的fd
    struct embedded_fd_set close_on_exec_init;    // exec()时关闭的文件描述符链表
    struct embedded_fd_set open_fds_init;         // 打开的文件描述符链表
    struct file         *fd_array[NR_OPEN_DEFAULT];    // 缺省的文件对象数组 
}
```

如果一个进程所打开的文件对象超过64个，内核将分配一个新数组，并将fdt指向它。所以对适当数量的文件对象的访问会执行的很快，因为它是对静态数组的操作。如果系统中有大量进程打开超过64个文件，为了优化新能，可以适当增大NR_OPEN_DEFAULT的预定义值
```
struct fs_struct {
    int             users;        // 用户数目
    rwlock_t        lock;         // 保护该结构体的锁
    int             umask;        // 掩码
    int             in_exec;      // 当前正在执行的文件
    struct path     root;         // 根目录路径
    struct path     pwd;          // 当前工作目录的路径
}
```
```
struct mmt_namespace {
    atomic_t            count;        // 结构的使用计数
    struct vfsmount     *root;        // 根目录的安装点对象
    struct list_head    list;         // 安装点链表
    wait_queue_head_t   poll;         // 轮询的等待队列
    int                 event;        // 事件计数
}
```

这3个数据结构都是通过进程描述符链接起来的。对多数进程来说，他们的描述符都指向唯一的file_struct和fs_struct结构体。但是对于使用克隆标志CLONE_FILES和CLONE_FS创建的进程，会共享这2个结构体。

默认情况下，所有进程共享同样的命名空间。只有在clone()操作时使用CLONE_NEWS标志，才会给进程一个唯一的命名空间结构体的拷贝。


# 块I/O层





















